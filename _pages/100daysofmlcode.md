---
permalink: /100daysofmlcode/
title: 100DaysOfMLCode
---

## Note
You won't "learn" machine learning in 30, 60, 100, 250, etc.. days. It's important to know how to build useful learning machines,  Only way to do it is training several non-trivial machines. It's a life long learning process. No hurry, Take your time and do it right.

![Test Image 3](/assets/images/100daysofmlcode/1.jpg)![Test Image 3](/assets/images/100daysofmlcode/1.jpg)![Test Image 3](/assets/images/100daysofmlcode/1.jpg)
<img src="/assets/images/100daysofmlcode/1.jpg" width="250" height="250"><img src="/assets/images/100daysofmlcode/1.jpg" width="250" height="250"><img src="/assets/images/100daysofmlcode/1.jpg" width="250" height="250">

#### Day 1 - Learn Python (Syntax, Keywords, Variables, Datatypes, Input & Output, Operators, Control flow, Loops, List, Tuple, Dictionary, Sets, Strings)
#### Day 2 - Learn Python (Functions, Modules, Packages, Object oriented programming)
#### Day 3 - Learn Numpy (Basic Functionalities, Matrix operations)
#### Day 4 - Learn Pandas (Basic Functionalities, Playing with dummy dataset)
#### Day 5 - Learn Linear algebra (Why LA, What is scalar, Vector, Matrix, Tensor, Unit vector, Dot product, Equation of line, Trnspose, Inverse, Determinant of a matrix)
#### Day 6 - Learn Linear algebra (Equation of line, Eigenvalues & Eigenvectors)
#### Day 7 - Learn Statistics (Why statistics for Machine learning?, Mean, Mode, Median, Probability density function, Cummulative distribution function, Gaussian/normal distribution, Symmetric distribution)
#### Day 8 - Learn Statistics (Kurtosis, Standard normal variate, Standardization, Normalization, Kernel density estimation, Central limit theorem)
#### Day 9 - Learn Statistics (Q-Q Plot, Different types of distribution and why and how we need to use them, Discrete and continious uniform distributions, Bernoulli and Binomial)
#### Day 10 - Learn Statistics (Lognormal, Power-Law distribution, Box-Cox transform, Covariance)
#### Day 11 - Learn Statistics (Pearson Correlation coefficient, Spearman Rank correlation coefficient, Correlation vs Causation, How to use them??, Confidence interval)
#### Day 12 - Learn Statistics (Bootstrapping, Confidence interval using bootstrapping, Hypothesis testing)
#### Day 13 - Learn Statistics (Resampling and permutation test, K-S test for similarity of two distributions)
#### Day 14 - Learn Statistics (Learn why statistics is important for data science, Where exactly we will use the concepts we learned, Try to apply these concepts on a problem and understand them)
#### Day 15 - Learn about Dimensionality reduction and PCA
#### Day 16 - Learn what exactly Machine learning and Artificial intelligence are? How Machine learning helps to achieve AI? Different types of learning algorithms in ML
#### Day 17 - Learn in-depth about Supervised learning, Unsupervised learning, Semi-supervised learning and Reinforcement learning
#### Day 18 - Learn EDA techniques like (Scatter plot, pair plots, PDF plots, CDF plots, Mean, Median, Standard deviation, Percentiles and Quantiles) and how and why these are used.
#### Day 19 - Learn EDA techniques like (IQR & MAD, Box-plot with whiskers, Violin plots, Summarizing plots, Univariate, Bivariate and Multivariate analysis, Contour Plot) and how and why these are used.
#### Day 20 - Learn about T-SNE
#### Day 21 - Learn Calculus (Maxima, Minima, Vector Calculus(Grad), Gradient descent, Learning rate, Loss function)
#### Day 22 - Learn about Performance metrics
#### Day 23 - You learned a lot of stuff till now. It's time to focus on gaining hands-on skills. Try taking and dataset from kaggle and do some statistical analysis and EDA to gain insights and understand the data.
#### Day 24 - Learn Gradient descent indetail and it's variants
#### Day 25 - Learn Linear regression
#### Day 26 & 27 - Take a dataset and try to apply linear regression algorithm using any library you want or you can write code from scratch. And learn more about the parameters it has.
#### Day 28 - Learn about Lasso and Ridge regression
#### Day 29 - Practice what you learned about lasso and ridge regression on a dataset
#### Day 30 - Learn about L1 & L2 regularizer and apply them in linear regression and see how the results are changing
#### Day 31 - Learn about Logistic Regression
#### Day 32 - Take a dataset and apply logistic regression on that and play around with it.
#### Day 33 - Learn about hyperparameter tuning and apply that on linear regression and logistic regression and check whether performance change is there are not.
#### Day 34 - Apply what you learned about hyperparameter tuning on linear regression and logistic regression and check whether performance change is there are not.
#### Day 35 - Learn about KNN (k nearest neighbor)
#### Day 36 - Practice how KNN works on different datasets (Classification and Regression) and apply hyperparameter tuning.
#### Day 37 - Learn about outliers and their impact on KNN, Linear regression and logistic regression.
#### Day 38 - Learn how to treat outliers
#### Day 39 - Learn how to handle categorical features
#### Day 40 - Learn how to handle numerical features
#### Day 41 - Try taking a dataset with both numerical and categorical features and apply different methods to those features and build a model. And check which method works best.
#### Day 42 - Learn about bias-variance tradeoff
#### Day 43 - Learn about best and worst cases of the algorithms
#### Day 44 - Learn about train, test and validation dataset and their differences.
#### Day 45 - Learn about importance of features and methods to select the best features.
#### Day 46 - Learn about curse of dimensionality 
#### Day 47 - Learn SVM (support vector machines) algorithm.
#### Day 48 - Learn about kernel trick, polynomial kernel and RBF kernel in SVM
#### Day 49 - Learn about SVR (support vector regression)
#### Day 50 - Practice what you learned SVM on a dataset + hyperparameter tuning
#### Day 51 - Practice what you learned SVM on a dataset + hyperparameter tuning + regularization
#### Day 52 - Practice what you learned SVR on a dataset + hyperparameter tuning + regularization
#### Day 53 - Learn Conditional probability, Bayes theorem and Naive Bayes
#### Day 54 - Take a toy dataset and apply Naive bayes algorithm
#### Day 55 - Learn about Laplace/additive smooting of Naive Bayes
#### Day 56 - Apply Naive bayes on imbalanced dataset, dataset with outliers and dataset with missing values + hyperparameter tuning + regularization
#### Day 57 - Learn how to handle nemerical features using Naive bayes (Gaussian Naive Bayes)
#### Day 58 - Learn the best and worst cases on Naive Bayes algorithm
#### Day 59 - Learn about Entropy, Information gain / Gini impurity of Decision trees
#### Day 60 - Take a small dataset and build decision tree from scratch
#### Day 61 - Learn how decision tree works on numerical features
#### Day 62 - Apply Decision trees on imbalanced dataset, dataset with outliers and dataset with missing values + hyperparameter tuning + regularization
#### Day 63 - Learn about decision tree regressor and experiment it on a toy dataset
#### Day 64 - Learn about Bootstrapped aggregration and Random forest
#### Day 65 - Apply Random forest on imbalanced dataset, dataset with outliers and dataset with missing values + hyperparameter tuning + regularization
#### Day 66 - Learn about Boosting and Gradient boosting
#### Day 67 - Apply Gradient boosting on imbalanced dataset, dataset with outliers and dataset with missing values + hyperparameter tuning + regularization
#### Day 68 - Learn about XGBoost and apply that on a toy dataset
#### Day 69 - Learn about stacking models
#### Day 70 - Apply what you learned about stacking models on a toy dataset
#### Day 71 - Learn about Cascading models
#### Day 72 - Apply what you learned about Cascading models on a toy dataset
#### Day 73 - Learn what is clustering and Unsupervised learning
#### Day 74 - Learn about K-Means algorithm 
#### Day 75 - Apply what you learned about K-Means algorithm on a toy dataset
#### Day 76 - Learn about K-Means++ algorithm 
#### Day 77 - Apply what you learned about K-Means++ algorithm on a toy dataset
#### Day 78 - Learn about K-Medoids algorithm 
#### Day 79 - Apply what you learned about K-Medoids algorithm on a toy dataset
#### Day 80 - Learn about limitations of K-Means algorithm
#### Day 81 - Learn about Agglomerative clustering algorithm 
#### Day 82 - Apply what you learned about Agglomerative clustering on a toy dataset
#### Day 83 - Learn about Divisive clustering algorithm 
#### Day 84 - Apply what you learned about Divisive clustering algorithm on a toy dataset
#### Day 85 - Learn about limitations of Hierarchical clustering algorithm
#### Day 86 - Learn about DBScan algorithm 
#### Day 87 - Apply what you learned about DBScan algorithm on a toy dataset
#### Day 88 - Learn about limitations of DBScan algorithm
#### Day 89 - Learn more about feature engineering in depth - 1
#### Day 90 - Learn more about feature engineering in depth - 2
#### Day 91 - Learn more about feature engineering in depth - 3
#### Day 92 - Learn more about feature engineering in depth - 4
#### Day 93 - Learn how to deploy your ML models using flask - 1
#### Day 94 - Learn how to deploy your ML models using flask - 2
#### Day 95 - Learn how to deploy your ML models on cloud(AWS) - 1
#### Day 96 - Learn how to deploy your ML models on cloud(AWS) - 2
#### Day 97 - Learn how to deploy your ML models on cloud(GCP) - 1
#### Day 98 -  Learn how to deploy your ML models on cloud(GCP) - 2
#### Day 99 - Learn how to deploy your ML models on cloud(Azure) - 1
#### Day 100 - Learn how to deploy your ML models on cloud(Azure) - 2